WARNING: Running python applications through 'pyspark' is deprecated as of Spark 1.0.
Use ./bin/spark-submit <python file>
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
:: loading settings :: url = jar:file:/opt/spark-1.6.3-bin-hadoop2.6/lib/spark-assembly-1.6.3-hadoop2.6.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
com.databricks#spark-csv_2.10 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0
	confs: [default]
	found com.databricks#spark-csv_2.10;1.3.0 in central
	found org.apache.commons#commons-csv;1.1 in central
	found com.univocity#univocity-parsers;1.5.1 in central
:: resolution report :: resolve 244ms :: artifacts dl 14ms
	:: modules in use:
	com.databricks#spark-csv_2.10;1.3.0 from central in [default]
	com.univocity#univocity-parsers;1.5.1 from central in [default]
	org.apache.commons#commons-csv;1.1 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent
	confs: [default]
	0 artifacts copied, 3 already retrieved (0kB/8ms)
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/08/02 16:53:55 INFO SparkContext: Running Spark version 1.6.3
17/08/02 16:53:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/02 16:53:56 WARN Utils: Your hostname, Abdul resolves to a loopback address: 127.0.1.1; using 192.168.217.149 instead (on interface ens33)
17/08/02 16:53:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
17/08/02 16:53:56 INFO SecurityManager: Changing view acls to: root
17/08/02 16:53:56 INFO SecurityManager: Changing modify acls to: root
17/08/02 16:53:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
17/08/02 16:53:56 INFO Utils: Successfully started service 'sparkDriver' on port 41994.
17/08/02 16:53:57 INFO Slf4jLogger: Slf4jLogger started
17/08/02 16:53:57 INFO Remoting: Starting remoting
17/08/02 16:53:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.217.149:36354]
17/08/02 16:53:57 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 36354.
17/08/02 16:53:57 INFO SparkEnv: Registering MapOutputTracker
17/08/02 16:53:57 INFO SparkEnv: Registering BlockManagerMaster
17/08/02 16:53:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8e37f1cc-a8fd-403c-a07b-ef99c7c9a2f2
17/08/02 16:53:57 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
17/08/02 16:53:57 INFO SparkEnv: Registering OutputCommitCoordinator
17/08/02 16:53:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/08/02 16:53:57 INFO SparkUI: Started SparkUI at http://192.168.217.149:4040
17/08/02 16:53:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/httpd-f9282199-e704-4512-bbd2-28ca72ba8851
17/08/02 16:53:57 INFO HttpServer: Starting HTTP Server
17/08/02 16:53:57 INFO Utils: Successfully started service 'HTTP file server' on port 36863.
17/08/02 16:53:57 INFO SparkContext: Added JAR file:/root/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar at http://192.168.217.149:36863/jars/com.databricks_spark-csv_2.10-1.3.0.jar with timestamp 1501707237706
17/08/02 16:53:57 INFO SparkContext: Added JAR file:/root/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar at http://192.168.217.149:36863/jars/org.apache.commons_commons-csv-1.1.jar with timestamp 1501707237707
17/08/02 16:53:57 INFO SparkContext: Added JAR file:/root/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar at http://192.168.217.149:36863/jars/com.univocity_univocity-parsers-1.5.1.jar with timestamp 1501707237707
17/08/02 16:53:57 INFO Utils: Copying /root/IoT/Project/Garbage/Project.py to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/Project.py
17/08/02 16:53:57 INFO SparkContext: Added file file:/root/IoT/Project/Garbage/Project.py at file:/root/IoT/Project/Garbage/Project.py with timestamp 1501707237891
17/08/02 16:53:57 INFO Utils: Copying /root/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.databricks_spark-csv_2.10-1.3.0.jar
17/08/02 16:53:57 INFO SparkContext: Added file file:/root/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar at file:/root/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar with timestamp 1501707237899
17/08/02 16:53:57 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/org.apache.commons_commons-csv-1.1.jar
17/08/02 16:53:57 INFO SparkContext: Added file file:/root/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar at file:/root/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar with timestamp 1501707237902
17/08/02 16:53:57 INFO Utils: Copying /root/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.univocity_univocity-parsers-1.5.1.jar
17/08/02 16:53:57 INFO SparkContext: Added file file:/root/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar at file:/root/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar with timestamp 1501707237905
17/08/02 16:53:58 INFO Executor: Starting executor ID driver on host localhost
17/08/02 16:53:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45727.
17/08/02 16:53:58 INFO NettyBlockTransferService: Server created on 45727
17/08/02 16:53:58 INFO BlockManagerMaster: Trying to register BlockManager
17/08/02 16:53:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45727 with 511.1 MB RAM, BlockManagerId(driver, localhost, 45727)
17/08/02 16:53:58 INFO BlockManagerMaster: Registered BlockManager
17/08/02 16:53:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 208.5 KB, free 510.9 MB)
17/08/02 16:53:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.3 KB, free 510.9 MB)
17/08/02 16:53:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45727 (size: 19.3 KB, free: 511.1 MB)
17/08/02 16:53:58 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
17/08/02 16:53:58 INFO FileInputFormat: Total input paths to process : 1
17/08/02 16:53:59 INFO SparkContext: Starting job: reduce at /root/IoT/Project/Garbage/Project.py:87
17/08/02 16:53:59 INFO DAGScheduler: Registering RDD 3 (reduceByKey at /root/IoT/Project/Garbage/Project.py:70)
17/08/02 16:53:59 INFO DAGScheduler: Got job 0 (reduce at /root/IoT/Project/Garbage/Project.py:87) with 1 output partitions
17/08/02 16:53:59 INFO DAGScheduler: Final stage: ResultStage 1 (reduce at /root/IoT/Project/Garbage/Project.py:87)
17/08/02 16:53:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/08/02 16:53:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/08/02 16:53:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /root/IoT/Project/Garbage/Project.py:70), which has no missing parents
17/08/02 16:53:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.6 KB, free 510.9 MB)
17/08/02 16:53:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KB, free 510.9 MB)
17/08/02 16:53:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45727 (size: 6.1 KB, free: 511.1 MB)
17/08/02 16:53:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/08/02 16:53:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /root/IoT/Project/Garbage/Project.py:70)
17/08/02 16:53:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/08/02 16:53:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2659 bytes)
17/08/02 16:53:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/08/02 16:53:59 INFO Executor: Fetching file:/root/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar with timestamp 1501707237905
17/08/02 16:53:59 INFO Utils: /root/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar has been previously copied to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.univocity_univocity-parsers-1.5.1.jar
17/08/02 16:53:59 INFO Executor: Fetching file:/root/IoT/Project/Garbage/Project.py with timestamp 1501707237891
17/08/02 16:53:59 INFO Utils: /root/IoT/Project/Garbage/Project.py has been previously copied to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/Project.py
17/08/02 16:53:59 INFO Executor: Fetching file:/root/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar with timestamp 1501707237902
17/08/02 16:53:59 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar has been previously copied to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/org.apache.commons_commons-csv-1.1.jar
17/08/02 16:53:59 INFO Executor: Fetching file:/root/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar with timestamp 1501707237899
17/08/02 16:53:59 INFO Utils: /root/.ivy2/jars/com.databricks_spark-csv_2.10-1.3.0.jar has been previously copied to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.databricks_spark-csv_2.10-1.3.0.jar
17/08/02 16:53:59 INFO Executor: Fetching http://192.168.217.149:36863/jars/com.univocity_univocity-parsers-1.5.1.jar with timestamp 1501707237707
17/08/02 16:53:59 INFO Utils: Fetching http://192.168.217.149:36863/jars/com.univocity_univocity-parsers-1.5.1.jar to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/fetchFileTemp518261180385212362.tmp
17/08/02 16:53:59 INFO Utils: /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/fetchFileTemp518261180385212362.tmp has been previously copied to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.univocity_univocity-parsers-1.5.1.jar
17/08/02 16:53:59 INFO Executor: Adding file:/tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.univocity_univocity-parsers-1.5.1.jar to class loader
17/08/02 16:53:59 INFO Executor: Fetching http://192.168.217.149:36863/jars/com.databricks_spark-csv_2.10-1.3.0.jar with timestamp 1501707237706
17/08/02 16:53:59 INFO Utils: Fetching http://192.168.217.149:36863/jars/com.databricks_spark-csv_2.10-1.3.0.jar to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/fetchFileTemp4234268904710902081.tmp
17/08/02 16:53:59 INFO Utils: /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/fetchFileTemp4234268904710902081.tmp has been previously copied to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.databricks_spark-csv_2.10-1.3.0.jar
17/08/02 16:53:59 INFO Executor: Adding file:/tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/com.databricks_spark-csv_2.10-1.3.0.jar to class loader
17/08/02 16:53:59 INFO Executor: Fetching http://192.168.217.149:36863/jars/org.apache.commons_commons-csv-1.1.jar with timestamp 1501707237707
17/08/02 16:53:59 INFO Utils: Fetching http://192.168.217.149:36863/jars/org.apache.commons_commons-csv-1.1.jar to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/fetchFileTemp1225957756810149121.tmp
17/08/02 16:53:59 INFO Utils: /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/fetchFileTemp1225957756810149121.tmp has been previously copied to /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/org.apache.commons_commons-csv-1.1.jar
17/08/02 16:53:59 INFO Executor: Adding file:/tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/userFiles-ffa7483d-56d2-426d-b87a-0e9a020541ee/org.apache.commons_commons-csv-1.1.jar to class loader
17/08/02 16:53:59 INFO HadoopRDD: Input split: file:/root/IoT/Project/Garbage/source/MyData_8000.csv:0+323309
17/08/02 16:53:59 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/08/02 16:53:59 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/08/02 16:53:59 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/08/02 16:53:59 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/08/02 16:53:59 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/08/02 16:53:59 INFO PythonRunner: Times: total = 395, boot = 186, init = 28, finish = 181
17/08/02 16:53:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2317 bytes result sent to driver
17/08/02 16:53:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 716 ms on localhost (1/1)
17/08/02 16:53:59 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /root/IoT/Project/Garbage/Project.py:70) finished in 0.734 s
17/08/02 16:53:59 INFO DAGScheduler: looking for newly runnable stages
17/08/02 16:53:59 INFO DAGScheduler: running: Set()
17/08/02 16:53:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/08/02 16:53:59 INFO DAGScheduler: failed: Set()
17/08/02 16:53:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/08/02 16:53:59 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[6] at reduce at /root/IoT/Project/Garbage/Project.py:87), which has no missing parents
17/08/02 16:53:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.3 KB, free 510.9 MB)
17/08/02 16:53:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.0 KB, free 510.9 MB)
17/08/02 16:53:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45727 (size: 4.0 KB, free: 511.1 MB)
17/08/02 16:53:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/08/02 16:53:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[6] at reduce at /root/IoT/Project/Garbage/Project.py:87)
17/08/02 16:53:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/08/02 16:53:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0,NODE_LOCAL, 2409 bytes)
17/08/02 16:53:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/08/02 16:54:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/02 16:54:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
17/08/02 16:54:00 INFO PythonRunner: Times: total = 26, boot = -137, init = 144, finish = 19
17/08/02 16:54:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1246 bytes result sent to driver
17/08/02 16:54:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 73 ms on localhost (1/1)
17/08/02 16:54:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/08/02 16:54:00 INFO DAGScheduler: ResultStage 1 (reduce at /root/IoT/Project/Garbage/Project.py:87) finished in 0.075 s
17/08/02 16:54:00 INFO DAGScheduler: Job 0 finished: reduce at /root/IoT/Project/Garbage/Project.py:87, took 0.991183 s
17/08/02 16:54:00 INFO SparkContext: Starting job: reduce at /root/IoT/Project/Garbage/Project.py:90
17/08/02 16:54:00 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 143 bytes
17/08/02 16:54:00 INFO DAGScheduler: Got job 1 (reduce at /root/IoT/Project/Garbage/Project.py:90) with 1 output partitions
17/08/02 16:54:00 INFO DAGScheduler: Final stage: ResultStage 3 (reduce at /root/IoT/Project/Garbage/Project.py:90)
17/08/02 16:54:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/08/02 16:54:00 INFO DAGScheduler: Missing parents: List()
17/08/02 16:54:00 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[7] at reduce at /root/IoT/Project/Garbage/Project.py:90), which has no missing parents
17/08/02 16:54:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 510.9 MB)
17/08/02 16:54:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 510.9 MB)
17/08/02 16:54:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:45727 (size: 4.0 KB, free: 511.1 MB)
17/08/02 16:54:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/08/02 16:54:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[7] at reduce at /root/IoT/Project/Garbage/Project.py:90)
17/08/02 16:54:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/08/02 16:54:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2, localhost, partition 0,NODE_LOCAL, 2409 bytes)
17/08/02 16:54:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
17/08/02 16:54:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/02 16:54:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/02 16:54:00 INFO PythonRunner: Times: total = 24, boot = -123, init = 125, finish = 22
17/08/02 16:54:00 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 1246 bytes result sent to driver
17/08/02 16:54:00 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 38 ms on localhost (1/1)
17/08/02 16:54:00 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/08/02 16:54:00 INFO DAGScheduler: ResultStage 3 (reduce at /root/IoT/Project/Garbage/Project.py:90) finished in 0.039 s
17/08/02 16:54:00 INFO DAGScheduler: Job 1 finished: reduce at /root/IoT/Project/Garbage/Project.py:90, took 0.071074 s
17/08/02 16:54:00 INFO SparkContext: Starting job: foreach at /root/IoT/Project/Garbage/Project.py:100
17/08/02 16:54:00 INFO DAGScheduler: Got job 2 (foreach at /root/IoT/Project/Garbage/Project.py:100) with 1 output partitions
17/08/02 16:54:00 INFO DAGScheduler: Final stage: ResultStage 5 (foreach at /root/IoT/Project/Garbage/Project.py:100)
17/08/02 16:54:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/08/02 16:54:00 INFO DAGScheduler: Missing parents: List()
17/08/02 16:54:00 INFO DAGScheduler: Submitting ResultStage 5 (PythonRDD[8] at foreach at /root/IoT/Project/Garbage/Project.py:100), which has no missing parents
17/08/02 16:54:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.1 KB, free 510.9 MB)
17/08/02 16:54:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.5 KB, free 510.9 MB)
17/08/02 16:54:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:45727 (size: 4.5 KB, free: 511.1 MB)
17/08/02 16:54:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/08/02 16:54:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (PythonRDD[8] at foreach at /root/IoT/Project/Garbage/Project.py:100)
17/08/02 16:54:00 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/08/02 16:54:00 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3, localhost, partition 0,NODE_LOCAL, 2409 bytes)
17/08/02 16:54:00 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
17/08/02 16:54:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/02 16:54:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms

Count for 43.9/-78.88: 146
total cost for 43.9/-78.88 = $730

Count for 43.89/-78.78: 61
total cost for 43.89/-78.78 = $305

Count for 43.91/-78.77: 42
total cost for 43.91/-78.77 = $210

Count for 43.89/-78.77: 24
total cost for 43.89/-78.77 = $120

Count for 43.93/-78.77: 10
total cost for 43.93/-78.77 = $50

Count for 43.93/-78.79: 28
total cost for 43.93/-78.79 = $140

Count for 43.93/-78.78: 24
total cost for 43.93/-78.78 = $120

Count for 43.91/-78.79: 144
total cost for 43.91/-78.79 = $720

Count for 43.89/-78.79: 105
total cost for 43.89/-78.79 = $525

Count for 43.93/-78.9: 35
total cost for 43.93/-78.9 = $175

Count for 43.93/-78.8: 33
total cost for 43.93/-78.8 = $165

Count for 43.93/-78.88: 34
total cost for 43.93/-78.88 = $170

Count for 43.93/-78.89: 39
total cost for 43.93/-78.89 = $195

Count for 43.93/-78.81: 51
total cost for 43.93/-78.81 = $255

Count for 43.93/-78.82: 35
total cost for 43.93/-78.82 = $175

Count for 43.93/-78.83: 32
total cost for 43.93/-78.83 = $160

Count for 43.93/-78.84: 36
total cost for 43.93/-78.84 = $180

Count for 43.89/-78.91: 66
total cost for 43.89/-78.91 = $330

Count for 43.89/-78.92: 23
total cost for 43.89/-78.92 = $115

Count for 43.93/-78.87: 38
total cost for 43.93/-78.87 = $190

Count for 43.88/-78.9: 51
total cost for 43.88/-78.9 = $255

Count for 43.88/-78.8: 32
total cost for 43.88/-78.8 = $160

Count for 43.88/-78.81: 57
total cost for 43.88/-78.81 = $285

Count for 43.88/-78.82: 40
total cost for 43.88/-78.82 = $200

Count for 43.88/-78.83: 32
total cost for 43.88/-78.83 = $160

Count for 43.88/-78.84: 36
total cost for 43.88/-78.84 = $180

Count for 43.88/-78.85: 28
total cost for 43.88/-78.85 = $140

Count for 43.89/-78.89: 99
total cost for 43.89/-78.89 = $495

Count for 43.88/-78.87: 35
total cost for 43.88/-78.87 = $175

Count for 43.88/-78.88: 37
total cost for 43.88/-78.88 = $185

Count for 43.89/-78.86: 113
total cost for 43.89/-78.86 = $565

Count for 43.89/-78.85: 106
total cost for 43.89/-78.85 = $530

Count for 43.89/-78.84: 126
total cost for 43.89/-78.84 = $630

Count for 43.89/-78.83: 117
total cost for 43.89/-78.83 = $585

Count for 43.89/-78.82: 124
total cost for 43.89/-78.82 = $620

Count for 43.89/-78.81: 101
total cost for 43.89/-78.81 = $505

Count for 43.9/-78.9: 135
total cost for 43.9/-78.9 = $675

Count for 43.9/-78.8: 155
total cost for 43.9/-78.8 = $775

Count for 43.89/-78.8: 116
total cost for 43.89/-78.8 = $580

Count for 43.89/-78.9: 131
total cost for 43.89/-78.9 = $655

Count for 43.88/-78.79: 30
total cost for 43.88/-78.79 = $150

Count for 43.88/-78.78: 21
total cost for 43.88/-78.78 = $105

Count for 43.88/-78.77: 8
total cost for 43.88/-78.77 = $40

Count for 43.91/-78.78: 130
total cost for 43.91/-78.78 = $650

Count for 43.88/-78.86: 25
total cost for 43.88/-78.86 = $125

Count for 43.92/-78.78: 65
total cost for 43.92/-78.78 = $325

Count for 43.92/-78.79: 100
total cost for 43.92/-78.79 = $500

Count for 43.92/-78.77: 22
total cost for 43.92/-78.77 = $110

Count for 43.89/-78.88: 113
total cost for 43.89/-78.88 = $565

Count for 43.88/-78.92: 5
total cost for 43.88/-78.92 = $25

Count for 43.88/-78.91: 26
total cost for 43.88/-78.91 = $130

Count for 43.88/-78.89: 43
total cost for 43.88/-78.89 = $215

Count for 43.9/-78.91: 100
total cost for 43.9/-78.91 = $500

Count for 43.93/-78.91: 25
total cost for 43.93/-78.91 = $125

Count for 43.9/-78.92: 31
total cost for 43.9/-78.92 = $155

Count for 43.9/-78.82: 130
total cost for 43.9/-78.82 = $650

Count for 43.9/-78.83: 161
total cost for 43.9/-78.83 = $805

Count for 43.9/-78.81: 154
total cost for 43.9/-78.81 = $770

Count for 43.9/-78.86: 130
total cost for 43.9/-78.86 = $650

Count for 43.9/-78.87: 158
total cost for 43.9/-78.87 = $790

Count for 43.9/-78.84: 127
total cost for 43.9/-78.84 = $635

Count for 43.9/-78.85: 130
total cost for 43.9/-78.85 = $650

Count for 43.93/-78.92: 10
total cost for 43.93/-78.92 = $50

Count for 43.9/-78.89: 156
total cost for 43.9/-78.89 = $780

Count for 43.91/-78.9: 155
total cost for 43.91/-78.9 = $775

Count for 43.91/-78.8: 149
total cost for 43.91/-78.8 = $745

Count for 43.92/-78.91: 81
total cost for 43.92/-78.91 = $405

Count for 43.92/-78.92: 27
total cost for 43.92/-78.92 = $135

Count for 43.93/-78.85: 37
total cost for 43.93/-78.85 = $185

Count for 43.93/-78.86: 36
total cost for 43.93/-78.86 = $180

Count for 43.91/-78.88: 118
total cost for 43.91/-78.88 = $590

Count for 43.91/-78.89: 148
total cost for 43.91/-78.89 = $740

Count for 43.91/-78.86: 146
total cost for 43.91/-78.86 = $730

Count for 43.91/-78.87: 130
total cost for 43.91/-78.87 = $650

Count for 43.91/-78.84: 140
total cost for 43.91/-78.84 = $700

Count for 43.91/-78.85: 122
total cost for 43.91/-78.85 = $610

Count for 43.91/-78.82: 147
total cost for 43.91/-78.82 = $735

Count for 43.91/-78.83: 138
total cost for 43.91/-78.83 = $690

Count for 43.91/-78.81: 118
total cost for 43.91/-78.81 = $590

Count for 43.92/-78.87: 106
total cost for 43.92/-78.87 = $530

Count for 43.92/-78.86: 112
total cost for 43.92/-78.86 = $560

Count for 43.92/-78.85: 115
total cost for 43.92/-78.85 = $575

Count for 43.92/-78.84: 111
total cost for 43.92/-78.84 = $555

Count for 43.92/-78.83: 113
total cost for 43.92/-78.83 = $565

Count for 43.92/-78.82: 122
total cost for 43.92/-78.82 = $610

Count for 43.92/-78.81: 87
total cost for 43.92/-78.81 = $435

Count for 43.92/-78.89: 105
total cost for 43.92/-78.89 = $525

Count for 43.92/-78.88: 114
total cost for 43.92/-78.88 = $570

Count for 43.91/-78.91: 104
total cost for 43.91/-78.91 = $520

Count for 43.92/-78.8: 90
total cost for 43.92/-78.8 = $450

Count for 43.92/-78.9: 108
total cost for 43.92/-78.9 = $540

Count for 43.9/-78.79: 139
total cost for 43.9/-78.79 = $695

Count for 43.9/-78.78: 102
total cost for 43.9/-78.78 = $510

Count for 43.9/-78.77: 32
total cost for 43.9/-78.77 = $160

Count for 43.91/-78.92: 50
total cost for 43.91/-78.92 = $250

Count for 43.89/-78.87: 121
total cost for 43.89/-78.87 = $605
17/08/02 16:54:00 INFO PythonRunner: Times: total = 53, boot = -48, init = 51, finish = 50
17/08/02 16:54:00 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 1245 bytes result sent to driver
17/08/02 16:54:00 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 70 ms on localhost (1/1)
17/08/02 16:54:00 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/08/02 16:54:00 INFO DAGScheduler: ResultStage 5 (foreach at /root/IoT/Project/Garbage/Project.py:100) finished in 0.072 s
17/08/02 16:54:00 INFO DAGScheduler: Job 2 finished: foreach at /root/IoT/Project/Garbage/Project.py:100, took 0.085704 s


total cost: $40000


total pickup points: 8000
17/08/02 16:54:00 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:-2
17/08/02 16:54:00 INFO DAGScheduler: Got job 3 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) with 1 output partitions
17/08/02 16:54:00 INFO DAGScheduler: Final stage: ResultStage 6 (saveAsTextFile at NativeMethodAccessorImpl.java:-2)
17/08/02 16:54:00 INFO DAGScheduler: Parents of final stage: List()
17/08/02 16:54:00 INFO DAGScheduler: Missing parents: List()
17/08/02 16:54:00 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[11] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
17/08/02 16:54:00 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 68.7 KB, free 510.8 MB)
17/08/02 16:54:00 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 25.2 KB, free 510.8 MB)
17/08/02 16:54:00 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:45727 (size: 25.2 KB, free: 511.1 MB)
17/08/02 16:54:00 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/08/02 16:54:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[11] at saveAsTextFile at NativeMethodAccessorImpl.java:-2)
17/08/02 16:54:00 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/08/02 16:54:00 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2670 bytes)
17/08/02 16:54:00 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)
17/08/02 16:54:00 INFO HadoopRDD: Input split: file:/root/IoT/Project/Garbage/source/MyData_8000.csv:0+323309
17/08/02 16:54:00 INFO PythonRunner: Times: total = 164, boot = -192, init = 206, finish = 150
17/08/02 16:54:00 INFO FileOutputCommitter: Saved output of task 'attempt_201708021654_0006_m_000000_4' to file:/root/IoT/Project/Garbage/result/_temporary/0/task_201708021654_0006_m_000000
17/08/02 16:54:00 INFO SparkHadoopMapRedUtil: attempt_201708021654_0006_m_000000_4: Committed
17/08/02 16:54:00 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 2401 bytes result sent to driver
17/08/02 16:54:00 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 315 ms on localhost (1/1)
17/08/02 16:54:00 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/08/02 16:54:00 INFO DAGScheduler: ResultStage 6 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) finished in 0.317 s
17/08/02 16:54:00 INFO DAGScheduler: Job 3 finished: saveAsTextFile at NativeMethodAccessorImpl.java:-2, took 0.343408 s
17/08/02 16:54:00 INFO SparkUI: Stopped Spark web UI at http://192.168.217.149:4040
17/08/02 16:54:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/02 16:54:00 INFO MemoryStore: MemoryStore cleared
17/08/02 16:54:00 INFO BlockManager: BlockManager stopped
17/08/02 16:54:00 INFO BlockManagerMaster: BlockManagerMaster stopped
17/08/02 16:54:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/02 16:54:00 INFO SparkContext: Successfully stopped SparkContext
17/08/02 16:54:00 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/08/02 16:54:00 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/08/02 16:54:01 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/08/02 16:54:01 INFO ShutdownHookManager: Shutdown hook called
17/08/02 16:54:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/httpd-f9282199-e704-4512-bbd2-28ca72ba8851
17/08/02 16:54:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072
17/08/02 16:54:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-d8f4f5ec-a7f5-48ff-973c-02addc7c7072/pyspark-6d061db3-b39f-4047-ba35-4ee0b8fb70a5
